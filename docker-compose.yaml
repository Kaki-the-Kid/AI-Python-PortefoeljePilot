services:
  portefoljepilot:
    container_name: portefoljepilot
    labels:
      cockpit.role: "CV-agent"
      cockpit.weight: "medium"
    deploy:
      resources:
        limits:
          cpus: "1.5"
        reservations:
          cpus: "1.0"
    build:
      context: /volume2/workspace/AI/AI-Active/AI-Python-PortefoeljePilot
      dockerfile: Dockerfile
    ports:
      - "5050:5000"
    volumes:
      - /volume2/workspace/AI/AI-Active/AI-Python-PortefoeljePilot:/app
    restart: "no"
    depends_on:
      - localai

  watchdog:
    container_name: watchdog
    labels:
      cockpit.role: "watchdog"
      cockpit.weight: "low"
    deploy:
      resources:
        limits:
          cpus: "0.25"
    build:
      context: /volume2/workspace/AI/AI-Active/AI-Python-PortefoeljePilot
      dockerfile: Dockerfile
    command:
      [
        "watchmedo",
        "auto-restart",
        "--directory=.",
        "--pattern=*.py",
        "--recursive",
        "--",
        "python",
        "watchdog_runner.py",
      ]
    volumes:
      - /volume2/workspace/AI/AI-Active/AI-Python-PortefoeljePilot:/app
    depends_on:
      - portefoljepilot
    restart: "no"

  localai:
    container_name: localai
    labels:
      cockpit.role: "AI-agent"
      cockpit.weight: "high"
    #image: ghcr.io/go-skynet/local-ai:latest
    image: localai/localai:latest
    ports:
      - "1234:8080"
    volumes:
      - /volume2/workspace/AI/models:/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    environment:
      - MODELS_PATH=${MODELS_PATH}
      - DEBUG=${DEBUG}
      - THREADS=${THREADS}
      - CONTEXT_SIZE=${CONTEXT_SIZE}
    restart: "no"
